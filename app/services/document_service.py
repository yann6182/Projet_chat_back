# app/services/document_service.py
from typing import Dict, List, BinaryIO, Optional
import os
import uuid
import docx2txt
import PyPDF2
import spacy
from pptx import Presentation
import language_tool_python
from spellchecker import SpellChecker
import re
import asyncio
import hashlib
from mistralai.client import MistralClient
from app.core.config import settings
from app.schemas.document import DocumentAnalysisResponse, SpellingError, GrammarError, LegalComplianceIssue
from app.services.chat_service import ChatService

class DocumentService:
    """
    Service pour l'analyse de documents.
    
    Ce service offre des fonctionnalit√©s d'analyse orthographique, grammaticale et juridique
    des documents. La fonctionnalit√© RAG (Retrieval-Augmented Generation) est utilis√©e pour
    l'analyse de conformit√© juridique avanc√©e.
    """
    def load_technical_terms(self):
        """
        Charge les termes techniques √† ignorer lors de la v√©rification orthographique.
        Les termes peuvent √™tre list√©s dans un fichier data/technical_terms.txt.
        """
        import os
        self.technical_terms = set()
        terms_file = os.path.join(os.path.dirname(__file__), '..', '..', 'data', 'technical_terms.txt')
        try:
            with open(terms_file, encoding='utf-8') as f:
                for line in f:
                    term = line.strip()
                    if term:
                        self.technical_terms.add(term.lower())
        except FileNotFoundError:
            pass
    
    def __init__(self, chat_service=None):
        # Services externes
        self.client = MistralClient(api_key=settings.MISTRAL_API_KEY)
        
        # Liste de termes techniques et mots fr√©quemment utilis√©s √† ne pas signaler
        self.technical_terms = set()
        self.load_technical_terms()
        
        # Termes juridiques importants pour la v√©rification de base
        self.legal_terms = [
            "siret", "tva", "responsabilit√©", "clause", "contrat", 
            "obligation", "condition", "facturation", "paiement", "d√©lai",
            "confidentialit√©", "propri√©t√©", "juridique", "l√©gal", "statut"
        ]
        
        # Liste de mots vides √† ignorer (articles, pr√©positions, etc.)
        self.stop_words = self._load_stop_words()
        
        # Initialiser les services d'IA
        self.model = "mistral-large-latest"  # Le mod√®le √† utiliser
          # Initialiser le service de chat qui sera utilis√© pour l'analyse RAG
        self.chat_service = chat_service
        self._setup_rag_service()
        
    def _setup_rag_service(self):
        """
        V√©rifie et configure le service RAG s'il n'est pas d√©j√† disponible
        """
        # Si le service de chat (RAG) n'est pas fourni, le cr√©er
        if not self.chat_service:
            from app.services.chat_service import ChatService
            try:
                print("üîç Tentative d'initialisation du service RAG pour l'analyse de documents...")
                self.chat_service = ChatService()
                
                # V√©rifier si le service RAG est actif
                rag_available = hasattr(self.chat_service, 'use_chroma') and self.chat_service.use_chroma
                db_available = hasattr(self.chat_service, 'chroma_service') and self.chat_service.chroma_service
                
                if rag_available and db_available:
                    print("‚úÖ Service RAG initialis√© et pr√™t pour l'analyse juridique")
                else:
                    print("‚ö†Ô∏è Service RAG initialis√© mais potentiellement incomplet:")
                    print(f"   - use_chroma: {rag_available}")
                    print(f"   - chroma_service: {db_available}")
            except Exception as e:
                print(f"‚ùå Erreur lors de l'initialisation du service RAG pour l'analyse de documents: {e}")
                # M√™me en cas d'erreur, on continue sans RAG
                self.chat_service = None
    
        # Charger le mod√®le spaCy pour l'analyse linguistique en fran√ßais
        try:
            self.nlp = spacy.load("fr_core_news_md")
        except IOError:
            # Fallback vers le mod√®le plus petit si le grand n'est pas disponible
            self.nlp = spacy.load("fr_core_news_sm")
        
        self.upload_dir = "data/user_uploads"
        os.makedirs(self.upload_dir, exist_ok=True)
        
        # Initialiser les outils de v√©rification avanc√©e
        self.grammar_tool = language_tool_python.LanguageTool('fr')
        self.spell_checker = SpellChecker(language='fr')
        
        # Cache pour les termes techniques √† ne pas signaler comme erreurs
        self.technical_terms_cache = set([
            # Termes informatiques courants
            "web", "angular", "react", "vue", "node", "javascript", "typescript", "html",
            "css", "api", "php", "sql", "nosql", "mongodb", "firebase", "aws", "azure",
            "frontend", "backend", "fullstack", "bootstrap", "jquery", "github", "gitlab",
            # Termes li√©s aux Juniors-Entreprises
            "cnje", "junior-entreprise", "je", "tva", "siret", "ape", "crm", "erp",
            # Abr√©viations courantes
            "cf", "etc", "ex", "nb", "url", "www", "http", "https", "app", "sdk"
        ])
        
        # Liste de termes juridiques sp√©cifiques aux Juniors Entreprises
        self.legal_terms = [
            "junior entreprise", "statut associatif", "CNJE", "√©tudiant entrepreneur",
            "prestation intellectuelle", "convention", "facturation", "TVA",
            "responsabilit√© civile professionnelle", "cotisation", "assembl√©e g√©n√©rale",
            "contrat de prestation", "devis", "facture", "TVA intracommunautaire",
            "responsabilit√© civile", "assurance", "statuts", "r√®glement int√©rieur",
            "conseil d'administration", "assembl√©e g√©n√©rale ordinaire", "AGO",
            "assembl√©e g√©n√©rale extraordinaire", "AGE", "bilan financier",
            "compte de r√©sultat", "tr√©sorier", "pr√©sident", "vice-pr√©sident",
            "secr√©taire g√©n√©ral", "commissaire aux comptes", "auditeur",
            "junior-entreprise", "JE", "√©tudiant", "√©cole", "universit√©",
            "formation", "comp√©tences", "mission", "client", "prospect",
            "commercial", "d√©veloppement", "qualit√©", "suivi", "livrable"
        ]
        
        # Expressions juridiques importantes √† v√©rifier
        self.legal_expressions = [
            r"num√©ro de TVA",
            r"TVA intracommunautaire",
            r"responsabilit√© civile professionnelle",
            r"assurance responsabilit√© civile",
            r"num√©ro SIRET",
            r"code APE",
            r"conditions g√©n√©rales",
            r"clause de confidentialit√©",
            r"propri√©t√© intellectuelle",
            r"droit d'auteur",
            r"d√©lai de paiement",
            r"p√©nalit√©s de retard",
            r"tribunal comp√©tent",
            r"droit applicable"
        ]
        
        # Dictionnaire de corrections courantes pour l'orthographe fran√ßaise
        self.common_corrections = {
            "contract": "contrat",
            "signature electronique": "signature √©lectronique",
            "assemblee": "assembl√©e",
            "president": "pr√©sident",
            "tresorier": "tr√©sorier",
            "prestation": "prestation",
            "junior-enterprise": "junior-entreprise",
            "cnje": "CNJE",
            "developper": "d√©velopper",
            "etudiant": "√©tudiant",
            "universite": "universit√©",
            "ecole": "√©cole"
        }
    
        
    async def save_document(self, file: BinaryIO, filename: str) -> str:
        """
        Sauvegarde un document t√©l√©charg√© et retourne son identifiant unique.
        
        Args:
            file: Le fichier t√©l√©charg√©
            filename: Le nom du fichier
            
        Returns:
            L'identifiant unique du document
        """
        # G√©n√©rer un ID unique pour le document
        document_id = str(uuid.uuid4())
        
        # D√©terminer l'extension du fichier
        _, ext = os.path.splitext(filename)
        
        # Cr√©er le chemin complet
        file_path = os.path.join(self.upload_dir, f"{document_id}{ext}")
        
        # Sauvegarder le fichier
        with open(file_path, "wb") as f:
            f.write(file.read())
            
        return document_id
        
    async def analyze_document(self, document_id: str) -> DocumentAnalysisResponse:
        """
        Analyse un document pour v√©rifier son orthographe, sa grammaire et sa conformit√© l√©gale.
        
        Args:
            document_id: L'identifiant du document √† analyser
            
        Returns:
            Le r√©sultat de l'analyse du document
        """
        # Trouver le fichier correspondant √† l'ID
        file_path, filename = self.find_document_by_id(document_id)
        
        if not file_path:
            raise FileNotFoundError(f"Document avec l'ID {document_id} non trouv√©")
            
        # Extraire le texte du document
        text = self.extract_text(file_path)
        
        # Pour les documents tr√®s longs, optimiser le texte pour l'analyse
        if len(text) > 20000:  # Si plus de 20 000 caract√®res
            optimized_text = self._optimize_text_for_analysis(text)
            print(f"Document optimis√© de {len(text)} √† {len(optimized_text)} caract√®res pour l'analyse")
        else:
            optimized_text = text
          # Analyser le texte
        spelling_errors = await self.check_spelling(optimized_text)
        grammar_errors = self.check_grammar(optimized_text)
        legal_compliance_issues = await self.check_legal_compliance(optimized_text)
        
        # Calculer un score de conformit√© global
        total_issues = len(spelling_errors) + len(grammar_errors) + len(legal_compliance_issues)
        # Ajuster le calcul du score pour √™tre plus √©quilibr√©
        max_allowed_issues = min(100, len(text) // 200)  # 1 erreur tous les 200 caract√®res maximum
        compliance_score = max(0.0, 1.0 - (total_issues / max_allowed_issues)) if total_issues > 0 else 1.0
        
        # G√©n√©rer des suggestions d'am√©lioration
        suggestions = self.generate_suggestions(text, spelling_errors, grammar_errors, legal_compliance_issues)
        
        return DocumentAnalysisResponse(
            document_id=document_id,
            filename=filename,
            spelling_errors=spelling_errors,
            grammar_errors=grammar_errors,
            legal_compliance_issues=legal_compliance_issues,
            overall_compliance_score=compliance_score,
            suggestions=suggestions
        )
        
    def find_document_by_id(self, document_id: str) -> tuple:
        """
        Recherche un document par son identifiant.
        
        Args:
            document_id: L'identifiant du document
            
        Returns:
            Un tuple contenant le chemin du fichier et son nom
        """
        for filename in os.listdir(self.upload_dir):
            if filename.startswith(document_id):
                return os.path.join(self.upload_dir, filename), filename
        return None, None
        
    def extract_text(self, file_path: str) -> str:
        """
        Extrait le texte d'un document selon son format.
        
        Args:
            file_path: Le chemin du fichier
            
        Returns:
            Le texte extrait du document
        """
        _, ext = os.path.splitext(file_path)
        ext = ext.lower()
        
        if ext == ".pdf":
            return self.extract_text_from_pdf(file_path)
        elif ext in [".docx", ".doc"]:
            return self.extract_text_from_docx(file_path)
        elif ext in [".pptx", ".ppt"]:
            return self.extract_text_from_pptx(file_path)
        elif ext == ".txt":
            with open(file_path, "r", encoding="utf-8") as f:
                return f.read()
        else:
            raise ValueError(f"Format de fichier non pris en charge: {ext}")
    
    def extract_text_from_pdf(self, file_path: str) -> str:
        """
        Extrait le texte d'un fichier PDF.
        
        Args:
            file_path: Le chemin du fichier PDF
            
        Returns:
            Le texte extrait du PDF
        """
        text = ""
        with open(file_path, "rb") as f:
            pdf_reader = PyPDF2.PdfReader(f)
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
        return text
        
    def extract_text_from_docx(self, file_path: str) -> str:
        """
        Extrait le texte d'un fichier DOCX.
        
        Args:
            file_path: Le chemin du fichier DOCX
            
        Returns:
            Le texte extrait du DOCX
        """
        return docx2txt.process(file_path)
        
    def extract_text_from_pptx(self, file_path: str) -> str:
        """
        Extrait le texte d'un fichier PowerPoint.
        
        Args:
            file_path: Le chemin du fichier PowerPoint
            
        Returns:
            Le texte extrait du PowerPoint
        """
        text = ""
        prs = Presentation(file_path)
        def extract_text_from_pptx(self, file_path: str) -> str:
            text = ""
            prs = Presentation(file_path)
            for slide in prs.slides:
                for shape in slide.shapes:
                    # on v√©rifie que la forme contient du texte
                    if getattr(shape, "has_text_frame", False):
                        text += shape.text + "\n"
            return text
    async def check_spelling(self, text: str) -> List[SpellingError]:
        """
        V√©rifie l'orthographe du texte avec un correcteur orthographique avanc√©,
        en utilisant Mistral pour valider les termes techniques et √©trangers.
        
        Args:
            text: Le texte √† v√©rifier
            
        Returns:
            Une liste d'erreurs d'orthographe
        """
        errors = []
        
        # Si le texte est vide, retourner imm√©diatement
        if not text or len(text) < 10:
            return errors
            
        # Limiter la taille du texte pour les tr√®s longs documents
        max_chars = 20000
        if len(text) > max_chars:
            print(f"Texte trop long ({len(text)} caract√®res), analyse limit√©e aux {max_chars} premiers caract√®res.")
            text = text[:max_chars]
        
        # Tokeniser le texte en mots - optimis√© pour inclure plus de caract√®res sp√©ciaux utilis√©s en programmation
        words = re.findall(r'\b[a-zA-Z√†√¢√§√©√®√™√´√Ø√Æ√¥√∂√π√ª√º√ß√Ä√Ç√Ñ√â√à√ä√ã√è√é√î√ñ√ô√õ√ú√á\-_]+\b', text)
        
        # Pour optimiser les performances, on va regrouper les mots par lots
        batch_size = 200  # Traiter plus de mots par lots pour am√©liorer les performances
        unique_words = set(word for word in words if len(word) >= 3)  # √âliminer les doublons et mots courts
        
        # Cr√©er une structure de donn√©es plus efficace pour retrouver les positions des mots
        word_positions = {}
        
        # Pr√©traitement : identifier les termes techniques en une seule passe
        technical_terms = set()
        for word in unique_words:
            if self._is_technical_term(word):
                technical_terms.add(word.lower())
        
        # Traiter les mots par lots pour r√©duire le nombre d'appels au correcteur orthographique
        word_batches = list(unique_words)
        
        # Filtrer les termes techniques et juridiques avant la v√©rification orthographique
        filtered_batch = [
            word for word in word_batches 
            if word.lower() not in technical_terms and
            not any(term.lower() == word.lower() for term in self.legal_terms)
        ]
            
        if not filtered_batch:
            return errors
                
        # V√©rifier tous les mots du lot en une seule op√©ration
        misspelled = self.spell_checker.unknown(filtered_batch)
        
        # Si aucune erreur n'est d√©tect√©e, retourner directement
        if not misspelled:
            return errors
            
        # Utiliser Mistral pour valider les termes qui semblent √™tre des erreurs
        # mais qui pourraient √™tre des termes techniques, anglais, etc.
        mistral_validations = await self._validate_with_mistral(list(misspelled))
        
        # Traiter seulement les mots que Mistral consid√®re comme invalides
        actual_misspelled = [word for word in misspelled if not mistral_validations.get(word, False)]
        
        # Pour chaque mot r√©ellement mal orthographi√©
        for word in actual_misspelled:
            # Calculer position seulement pour les mots mal orthographi√©s (paresseux)
            if word not in word_positions:
                # Rechercher toutes les occurrences du mot dans le texte
                pattern = r'\b' + re.escape(word) + r'\b'
                for match in re.finditer(pattern, text):
                    position = {"start": match.start(), "end": match.end()}
                    
                    # Obtenir des suggestions de correction avec mise en cache pour des appels r√©p√©t√©s
                    candidates = self.spell_checker.candidates(word.lower())
                    suggestions = list(candidates)[:3] if candidates else []
                    
                    # V√©rifier avec le dictionnaire de corrections personnalis√©
                    if word.lower() in self.common_corrections:
                        suggestions.insert(0, self.common_corrections[word.lower()])
                    
                    if suggestions:  # Seulement ajouter si on a des suggestions
                        errors.append(
                            SpellingError(
                                word=word,
                                position=position,
                                suggestions=suggestions
                            )
                        )
                    break  # Ne prendre que la premi√®re occurrence pour √©viter les doublons
        
        return errors
        
    def check_grammar(self, text: str) -> List[GrammarError]:
        """
        V√©rifie la grammaire du texte avec LanguageTool.
        
        Args:
            text: Le texte √† v√©rifier
            
        Returns:
            Une liste d'erreurs grammaticales
        """
        errors = []
        
        # Si le texte est vide, retourner imm√©diatement
        if not text or len(text) < 10:
            return errors
        
        # Optimisation pour les textes longs - analyse par sections
        max_section_length = 5000  # Longueur maximale de chaque section
        
        # Estimer le temps d'analyse en fonction de la longueur du texte
        estimated_time_per_char = 0.0001  # Estimation tr√®s approximative
        estimated_time_seconds = len(text) * estimated_time_per_char
        
        # Approche adaptative en fonction de la longueur
        if len(text) <= max_section_length:
            # Pour les textes courts, analyser tout le document
            return self._check_grammar_section(text, 0)
        elif len(text) <= 15000:
            # Pour les textes moyens, analyser le d√©but et la fin
            section_size = max_section_length // 2  # Moiti√© de la taille maximale
            
            # Analyser le d√©but du document
            errors.extend(self._check_grammar_section(text[:section_size], 0))
            
            # Analyser la fin du document
            if len(text) > section_size + 500:  # √âviter le chevauchement
                start_pos = len(text) - section_size
                errors.extend(self._check_grammar_section(text[-section_size:], start_pos))
                
            print(f"Texte de taille moyenne ({len(text)} caract√®res), analyse limit√©e au d√©but et √† la fin ({2 * section_size} caract√®res).")
        else:
            # Pour les textes tr√®s longs, analyser d√©but, milieu et des √©chantillons
            print(f"Texte long ({len(text)} caract√®res), analyse √©chantillonn√©e.")
            
            # 1. D√©but du document (40%)
            start_portion = int(max_section_length * 0.4)
            errors.extend(self._check_grammar_section(text[:start_portion], 0))
            
            # 2. Milieu du document (30%)
            mid_point = len(text) // 2
            mid_portion = int(max_section_length * 0.3) 
            mid_start = mid_point - (mid_portion // 2)
            mid_text = text[mid_start:mid_start + mid_portion]
            errors.extend(self._check_grammar_section(mid_text, mid_start))
            
            # 3. Fin du document (30%)
            end_portion = int(max_section_length * 0.3)
            end_text = text[-end_portion:]
            errors.extend(self._check_grammar_section(end_text, len(text) - end_portion))
            
            # 4. √âchantillons al√©atoires pour les tr√®s longs documents
            if len(text) > 50000:
                import random
                # Prendre quelques √©chantillons al√©atoires de paragraphes
                paragraphs = text.split('\n\n')
                if len(paragraphs) > 5:
                    samples = random.sample(paragraphs, min(5, len(paragraphs) // 10))
                    for sample in samples:
                        if len(sample) > 100:  # Ignorer les paragraphes trop courts
                            # Trouver la position du paragraphe dans le texte original
                            sample_pos = text.find(sample)
                            if sample_pos != -1:
                                errors.extend(self._check_grammar_section(sample, sample_pos))
        
        return errors
    
    def _check_grammar_section(self, text_section: str, offset: int = 0) -> List[GrammarError]:
        """
        V√©rifie la grammaire d'une section de texte.
        
        Args:
            text_section: La section de texte √† v√©rifier
            offset: Position de d√©but de la section dans le texte complet
            
        Returns:
            Liste des erreurs grammaticales
        """
        errors = []
        
        try:
            # Utiliser LanguageTool pour la v√©rification grammaticale
            # Configuration optimis√©e pour r√©duire les faux positifs
            matches = self.grammar_tool.check(
                text_section,
                # D√©sactiver certaines r√®gles qui g√©n√®rent souvent des faux positifs
                disabled_rules=['WHITESPACE_RULE', 'UPPERCASE_SENTENCE_START']
            )
            
            # Construire un ensemble de termes techniques pour une recherche plus rapide
            technical_terms = set()
            words = re.findall(r'\b\w+\b', text_section)
            for word in set(words):
                if self._is_technical_term(word):
                    technical_terms.add(word.lower())
            
            for match in matches:
                # Filtrer les erreurs non pertinentes (orthographe d√©j√† v√©rifi√©e ailleurs)
                if match.category in ['TYPOS', 'SPELLING', 'CASING']:
                    continue
                
                # V√©rifier si le texte en erreur est un terme technique
                error_text = text_section[match.offset:match.offset + match.errorLength]
                
                # Ignorer les erreurs pour les termes techniques
                if error_text.lower() in technical_terms or self._is_technical_term(error_text):
                    continue
                    
                # Optimiser : Filtrer les cas o√π le match contient un terme technique
                contains_tech_term = any(term in error_text.lower() for term in technical_terms)
                if contains_tech_term:
                    continue
                
                # Ajuster la position pour correspondre au texte complet
                adjusted_start = match.offset + offset
                adjusted_end = adjusted_start + match.errorLength
                
                error = GrammarError(
                    text=error_text,
                    position={"start": adjusted_start, "end": adjusted_end},
                    message=match.message,
                    suggestions=match.replacements[:3]  # Limiter √† 3 suggestions
                )
                errors.append(error)
                
        except Exception as e:
            print(f"Erreur lors de la v√©rification grammaticale de la section: {e}")
            # Fallback vers l'ancienne m√©thode si LanguageTool √©choue
            try:
                fallback_errors = self._check_grammar_fallback(text_section)
                # Ajuster les positions des erreurs
                for error in fallback_errors:
                    error.position["start"] += offset
                    error.position["end"] += offset
                errors.extend(fallback_errors)
            except Exception:
                # En cas d'√©chec du fallback, simplement ignorer cette section
                pass
            
        return errors
    async def check_legal_compliance(self, text: str) -> List[LegalComplianceIssue]:
        """
        V√©rifie la conformit√© l√©gale du texte en analysant avec la base de connaissances.
        
        Args:
            text: Le texte √† v√©rifier
            
        Returns:
            Une liste de probl√®mes de conformit√© l√©gale
        """
        issues = []
        
        # 1. V√©rifications automatiques de base
        issues.extend(self._check_basic_legal_requirements(text))
        
        # 2. Analyse avanc√©e avec la base de connaissances (RAG) - R√âACTIV√âE avec optimisations
        try:
            # Pour les documents tr√®s longs, limiter l'analyse √† 3000 caract√®res pertinents
            max_length = 3000
            if len(text) > max_length:
                # Prendre les 1500 premiers caract√®res (d√©but du document)
                start_text = text[:1500]
                # Chercher des mots-cl√©s juridiques importants
                keywords = ["responsabilit√©", "conditions g√©n√©rales", "TVA", "clause", "propri√©t√©", 
                           "contrat", "statut", "association", "CNJE", "junior-entreprise",
                           "siret", "facturation", "r√®glement", "assembl√©e", "cotisation"]
                legal_chunks = []
                
                # Parcourir les mots-cl√©s et extraire le contexte autour d'eux
                for keyword in keywords:
                    if keyword in text.lower():
                        idx = text.lower().find(keyword)
                        if idx >= 0:
                            # Prendre 200 caract√®res autour du mot-cl√©
                            start_idx = max(0, idx - 100)
                            end_idx = min(len(text), idx + 100)
                            legal_chunks.append(text[start_idx:end_idx])
                
                # Combiner le d√©but du document et les sections pertinentes
                text_to_analyze = start_text + "\n...\n" + "\n".join(legal_chunks)
                
                # Limiter √† la taille maximale si n√©cessaire
                if len(text_to_analyze) > max_length:
                    text_to_analyze = text_to_analyze[:max_length]
                    
                legal_analysis = await self._analyze_with_knowledge_base(text_to_analyze)
            else:
                legal_analysis = await self._analyze_with_knowledge_base(text)
            
            issues.extend(legal_analysis)
            
        except Exception as e:
            print(f"Erreur lors de l'analyse juridique avanc√©e: {e}")
            # En cas d'erreur, ajouter une notification
            issues.append(
                LegalComplianceIssue(
                    text="",
                    position={"start": 0, "end": 0},
                    issue_type="Erreur d'analyse RAG",
                    description="Une erreur s'est produite lors de l'analyse avanc√©e avec la base de connaissances.",
                    recommendation="Veuillez v√©rifier l'√©tat de la base de connaissances et r√©essayer."
                )
            )
        
        return issues
    
    def _check_basic_legal_requirements(self, text: str) -> List[LegalComplianceIssue]:
        """
        V√©rifie les exigences l√©gales de base.
        """
        issues = []
        text_lower = text.lower()
        
        # V√©rifier la pr√©sence de termes juridiques importants
        missing_terms = []
        for term in self.legal_terms:
            if term not in text_lower:
                missing_terms.append(term)
        
        if len(missing_terms) > len(self.legal_terms) * 0.7:  # Si plus de 70% des termes manquent
            issues.append(
                LegalComplianceIssue(
                    text="",
                    position={"start": 0, "end": 0},
                    issue_type="Termes juridiques manquants",
                    description=f"Document incomplet : plusieurs termes juridiques importants sont absents. Exemples manquants : {', '.join(missing_terms[:5])}",
                    recommendation="Ajoutez les termes juridiques appropri√©s selon le type de document (contrat, statuts, etc.)."
                )
            )
        
        # V√©rifications sp√©cifiques selon le contenu
        if "tva" in text_lower and "num√©ro de tva" not in text_lower and "tva intracommunautaire" not in text_lower:
            tva_pos = text_lower.find("tva")
            issues.append(
                LegalComplianceIssue(
                    text="TVA",
                    position={"start": tva_pos, "end": tva_pos + 3},
                    issue_type="Mention l√©gale incompl√®te",
                    description="La TVA est mentionn√©e mais le num√©ro de TVA intracommunautaire n'est pas pr√©cis√©.",
                    recommendation="Ajoutez le num√©ro de TVA intracommunautaire de votre Junior-Entreprise."
                )
            )
        
        # V√©rifier les mentions obligatoires pour les contrats
        if any(word in text_lower for word in ["contrat", "prestation", "service"]):
            contract_issues = self._check_contract_requirements(text)
            issues.extend(contract_issues)
        
        # V√©rifier les statuts d'association
        if any(word in text_lower for word in ["statuts", "association", "assembl√©e"]):
            statute_issues = self._check_statute_requirements(text)
            issues.extend(statute_issues)
        
        return issues
    
    def _check_contract_requirements(self, text: str) -> List[LegalComplianceIssue]:
        """
        V√©rifie les exigences sp√©cifiques aux contrats.
        """
        issues = []
        text_lower = text.lower()
        
        required_clauses = [
            ("responsabilit√© civile", "clause de responsabilit√© civile"),
            ("conditions g√©n√©rales", "conditions g√©n√©rales de vente/prestation"),
            ("d√©lai", "d√©lais d'ex√©cution"),
            ("paiement", "conditions de paiement"),
            ("propri√©t√© intellectuelle", "clause de propri√©t√© intellectuelle")
        ]
        
        for clause, description in required_clauses:
            if clause not in text_lower:
                issues.append(
                    LegalComplianceIssue(
                        text="",
                        position={"start": 0, "end": 0},
                        issue_type="Clause contractuelle manquante",
                        description=f"Clause manquante : {description}",
                        recommendation=f"Ajoutez une {description} dans votre contrat."
                    )
                )
        
        return issues
    
    def _check_statute_requirements(self, text: str) -> List[LegalComplianceIssue]:
        """
        V√©rifie les exigences sp√©cifiques aux statuts d'association.
        """
        issues = []
        text_lower = text.lower()
        
        required_elements = [
            ("objet social", "d√©finition de l'objet social"),
            ("si√®ge social", "adresse du si√®ge social"),
            ("conseil d'administration", "composition du conseil d'administration"),
            ("assembl√©e g√©n√©rale", "modalit√©s d'assembl√©e g√©n√©rale"),
            ("dissolution", "conditions de dissolution")
        ]
        
        for element, description in required_elements:
            if element not in text_lower:
                issues.append(
                    LegalComplianceIssue(
                        text="",
                        position={"start": 0, "end": 0},
                        issue_type="√âl√©ment statutaire manquant",
                        description=f"√âl√©ment manquant : {description}",
                        recommendation=f"Les statuts doivent inclure {description}."
                    )
                )
        
        return issues
    async def _analyze_with_knowledge_base(self, text: str) -> List[LegalComplianceIssue]:
        """
        Analyse le document avec la base de connaissances juridique.
        
        Cette m√©thode utilise RAG pour extraire des informations pertinentes
        de la base de connaissances juridique.
        """
        issues = []
        
        try:            # Pr√©parer la requ√™te pour l'analyse juridique avec demande EXPLICITE de citations
            legal_query = f"""
            Analysez ce document du point de vue juridique en vous basant UNIQUEMENT sur votre base de connaissances sur les Junior-Entreprises.
            Identifiez les √©l√©ments non conformes au droit fran√ßais et aux sp√©cificit√©s des Junior-Entreprises.
            
            Document √† analyser :
            {text[:2000]}
            
            Recherchez sp√©cifiquement :
            1. Les mentions l√©gales obligatoires manquantes
            2. Les clauses contractuelles non conformes
            3. Les √©l√©ments statutaires incorrects
            4. Les obligations fiscales et sociales non respect√©es
            
            INSTRUCTIONS STRICTES:
            - Pour CHAQUE probl√®me identifi√©, vous DEVEZ suivre EXACTEMENT ce format en trois parties:
            
            PROBL√àME: [Description claire et pr√©cise du probl√®me identifi√©]
            CITATION: [Citation EXACTE et TEXTUELLE provenant de votre base de connaissances juridique]
            RECOMMANDATION: [Votre recommandation concr√®te pour corriger le probl√®me]
            
            - Ne JAMAIS omettre la section CITATION qui doit contenir du texte exact de votre base de connaissances
            - Si vous ne trouvez pas de citation pertinente dans votre base de connaissances, NE MENTIONNEZ PAS ce probl√®me
            - Inclure au minimum 2 citations pertinentes de votre base de connaissances
            
            IMPORTANT: Je vais v√©rifier la pr√©sence des citations exactes. Si elles sont absentes, votre analyse sera consid√©r√©e comme incompl√®te.
            """
              # Utiliser le service de chat pour analyser avec la base de connaissances
            from app.schemas.chat import ChatRequest
            import hashlib
            
            # G√©n√©rer une cl√© de cache robuste bas√©e sur le contenu du texte
            text_hash = hashlib.md5(text[:1500].encode('utf-8')).hexdigest()
            cache_key = f"legal_analysis_v2_{text_hash}"  # Ajouter un pr√©fixe v2 pour forcer la mise √† jour
            
            # V√©rifier si la requ√™te existe dans le cache pour √©viter des requ√™tes r√©p√©titives
            from app.services.cache_service import get_cache
            cache = get_cache()
            cached_response = cache.get(cache_key)
            
            if cached_response and len(cached_response) > 200:  # V√©rifier que la r√©ponse est suffisamment longue
                # Si la r√©ponse est en cache et semble valide, l'utiliser directement
                response_text = cached_response
                print(f"‚úÖ Utilisation d'une r√©ponse mise en cache pour l'analyse juridique ({len(response_text)} caract√®res)")
                
                # V√©rifier si la r√©ponse en cache contient des √©l√©ments au format structur√© attendu
                if "PROBL√àME:" not in response_text.upper() and "CITATION:" not in response_text.upper():
                    print("‚ö†Ô∏è La r√©ponse en cache ne semble pas contenir le format structur√© attendu, force d'une nouvelle requ√™te")
                    cached_response = None  # Forcer une nouvelle requ√™te
            else:
                cached_response = None
                
            if not cached_response:
                print(f"üîÑ G√©n√©ration d'une nouvelle analyse juridique RAG")
                # Sinon, faire la requ√™te
                chat_request = ChatRequest(query=legal_query)
                
                # Cr√©er une conversation temporaire pour l'analyse
                import uuid
                temp_conversation_id = f"legal_analysis_{uuid.uuid4()}"
                
                try:
                    # Analyser avec le service de chat (qui utilise la base de connaissances)
                    response = await self.chat_service.process_query(
                        request=chat_request,
                        conversation_id=temp_conversation_id,
                        user_id=1  # Utilisateur syst√®me pour l'analyse
                    )
                    
                    if response and hasattr(response, 'response') and response.response:
                        response_text = response.response
                        print(f"‚úÖ R√©ponse RAG obtenue ({len(response_text)} caract√®res)")
                        
                        # V√©rifier la pr√©sence d'√©l√©ments au format attendu
                        if "PROBL√àME:" in response_text or "CITATION:" in response_text:
                            # Mettre en cache la r√©ponse pour une utilisation future (TTL de 1 jour)
                            cache.set(cache_key, response_text, ttl=86400, persist=True)
                            print("üíæ R√©ponse mise en cache pour utilisation future")
                        else:
                            print("‚ö†Ô∏è Format attendu non d√©tect√© dans la r√©ponse")
                    else:
                        raise Exception("Pas de r√©ponse du service de chat ou r√©ponse invalide")
                except Exception as e:
                    # Capture de l'erreur sp√©cifique pour un meilleur diagnostic
                    print(f"‚ùå Erreur lors de l'appel √† process_query: {str(e)}")
                    # Essayer d'utiliser une r√©ponse g√©n√©rique si disponible
                    response_text = "L'analyse juridique n'a pas pu √™tre effectu√©e en raison d'un probl√®me technique."
                    raise Exception(f"√âchec de l'analyse RAG: {str(e)}")
            
            # Parser la r√©ponse pour extraire les probl√®mes juridiques
            legal_issues = self._parse_legal_analysis_response(response_text)
            issues.extend(legal_issues)
        
        except Exception as e:
            print(f"Erreur lors de l'analyse avec la base de connaissances: {e}")
            # En cas d'erreur, ajouter un conseil g√©n√©ral
            issues.append(
                LegalComplianceIssue(
                    text="",
                    position={"start": 0, "end": 0},
                    issue_type="Analyse juridique recommand√©e",
                    description="Une erreur s'est produite lors de l'analyse avec la base de connaissances.",
                    recommendation="Consultez un expert juridique ou votre r√©f√©rent CNJE pour valider la conformit√© de ce document."
                )
            )
        
        return issues
    def _parse_legal_analysis_response(self, response_text: str) -> List[LegalComplianceIssue]:
        """
        Parse la r√©ponse de l'analyse juridique pour extraire les probl√®mes.
        Cette m√©thode am√©lior√©e recherche sp√©cifiquement le format structur√© avec citations.
        """
        issues = []
        
        # Format structur√© avec extraction de bloc multilignes
        import re
        
        # Motif pour extraire des blocs complets "PROBL√àME:...CITATION:...RECOMMANDATION..."
        block_pattern = r"PROBL√àME\s*:\s*([\s\S]*?)(?:CITATION\s*:\s*([\s\S]*?))?(?:RECOMMANDATION\s*:\s*([\s\S]*?))?(?=PROBL√àME|$)"
        
        # Rechercher tous les blocs dans la r√©ponse
        block_matches = re.finditer(block_pattern, response_text, re.IGNORECASE)
        
        for block_match in block_matches:
            # Extraire chaque partie du bloc
            problem_text = block_match.group(1).strip() if block_match.group(1) else ""
            citation_text = block_match.group(2).strip() if block_match.group(2) else ""
            recommendation_text = block_match.group(3).strip() if block_match.group(3) else ""
            
            # Si on n'a pas de citation dans le format structur√©, essayer de l'extraire avec des patterns alternatifs
            if not citation_text:
                # Rechercher des citations entre guillemets dans le probl√®me
                quote_pattern = r'[¬´"]([^¬´"]+)[¬ª"]'
                quote_matches = re.findall(quote_pattern, problem_text)
                if quote_matches:
                    citation_text = "; ".join(quote_matches)
              # Si on a trouv√© au moins un probl√®me et une citation
            if problem_text:
                # Log de d√©boggage pour v√©rifier l'extraction
                print(f"Probl√®me extrait: {problem_text[:50]}...")
                print(f"Citation extraite: {citation_text[:50]}..." if citation_text else "Pas de citation")
                
                # Ne cr√©er l'issue que si on a une citation ou si on est en mode debug
                if citation_text:
                    issues.append(
                        LegalComplianceIssue(
                            text=citation_text,
                            position={"start": 0, "end": 0},
                            issue_type="Probl√®me juridique identifi√©",
                            description=problem_text,
                            recommendation=recommendation_text or "Consultez un expert juridique pour plus d'informations."
                        )
                    )
        
        # M√©thode am√©lior√©e pour extraire les citations si le format structur√© a √©chou√©
        if not issues:
            # Phase 1: Rechercher explicitement des paires probl√®me-citation
            problem_citation_pattern = r'(?:probl√®me|non-conformit√©|issue|erreur)[^\n]*?\:([^\n]+)(?:[^\n]*?citation[^\n]*?\:([^\n]+))'
            pc_matches = re.finditer(problem_citation_pattern, response_text, re.IGNORECASE)
            
            for pc_match in pc_matches:
                problem_desc = pc_match.group(1).strip()
                citation = pc_match.group(2).strip() if pc_match.group(2) else ""
                
                if citation:
                    issues.append(
                        LegalComplianceIssue(
                            text=citation,
                            position={"start": 0, "end": 0},
                            issue_type="Citation juridique",
                            description=problem_desc,
                            recommendation="V√©rifiez la conformit√© avec les exigences juridiques."
                        )
                    )
            
            # Phase 2: Rechercher des citations entre guillemets si toujours pas de r√©sultats
            if not issues:
                # Rechercher des mots-cl√©s indiquant des probl√®mes juridiques
                problem_indicators = [
                    "manque", "manquant", "absent", "non conforme", "incorrecte", 
                    "obligatoire", "doit", "devrait", "n√©cessaire", "requis", "ill√©gal", 
                    "non-respect", "violation", "interdit"
                ]
                
                # Rechercher des citations avec diff√©rents types de guillemets
                citation_pattern = r'[¬´"]([^"¬ª]{15,})[¬ª"]'
                citation_matches = re.finditer(citation_pattern, response_text)
                
                for match in citation_matches:
                    citation = match.group(1).strip()
                    # Trouver le contexte avant et apr√®s la citation
                    start_pos = max(0, match.start() - 150)
                    end_pos = min(len(response_text), match.end() + 150)
                    context = response_text[start_pos:end_pos]
                    
                    # V√©rifier si le contexte contient un indicateur de probl√®me
                    if any(indicator in context.lower() for indicator in problem_indicators):
                        # Extraire une description sensible du contexte
                        context_before = response_text[start_pos:match.start()].strip()
                        sentences_before = [s.strip() for s in context_before.split('.') if s.strip()]
                        description = sentences_before[-1] if sentences_before else "Probl√®me juridique identifi√©"
                        
                        issues.append(
                            LegalComplianceIssue(
                                text=citation,
                                position={"start": 0, "end": 0},
                                issue_type="Citation juridique importante",
                                description=description,
                                recommendation="V√©rifiez la conformit√© avec cette r√©f√©rence juridique."
                            )
                        )
              # Phase 3: Dernier recours - extraire des recommandations g√©n√©rales s'il n'y a toujours pas de citations
            if not issues:
                # Rechercher des phrases avec des recommandations
                recommendation_patterns = [
                    r"je (?:vous )?recommande[^.]+\.",
                    r"il (?:est|serait) (?:fortement |vivement )?recommand√©[^.]+\.",
                    r"il (?:est|serait) (?:n√©cessaire|important|obligatoire)[^.]+\."
                ]
                
                for pattern in recommendation_patterns:
                    rec_matches = re.finditer(pattern, response_text, re.IGNORECASE)
                    for rec_match in rec_matches:
                        recommendation = rec_match.group(0).strip()
                        issues.append(
                            LegalComplianceIssue(
                                text="",
                                position={"start": 0, "end": 0},
                                issue_type="Recommandation juridique",
                                description="Analyse juridique: une recommandation a √©t√© identifi√©e",
                                recommendation=recommendation
                            )
                        )
                        
            # Si aucune citation n'a √©t√© trouv√©e malgr√© tous les efforts, ajouter un message d'erreur explicite
            if not issues:
                print("‚ö†Ô∏è Aucune citation juridique extraite de la r√©ponse")
                issues.append(
                    LegalComplianceIssue(
                        text="",
                        position={"start": 0, "end": 0},
                        issue_type="Analyse juridique incompl√®te",
                        description="L'analyse n'a pas pu identifier de citations sp√©cifiques de la base de connaissances juridique.",
                        recommendation="Essayez de reformuler ou d'enrichir le document pour une analyse plus pr√©cise."
                    )
                )
                
                # Log de la r√©ponse compl√®te pour le d√©bogage
                print(f"R√©ponse RAG compl√®te (tronqu√©e): {response_text[:500]}...")
        
        return issues
        
    def generate_suggestions(self, text: str, spelling_errors: List[SpellingError], 
                            grammar_errors: List[GrammarError], 
                            legal_issues: List[LegalComplianceIssue]) -> List[str]:
        """
        G√©n√®re des suggestions d'am√©lioration bas√©es sur les erreurs d√©tect√©es.
        
        Args:
            text: Le texte analys√©
            spelling_errors: Les erreurs d'orthographe d√©tect√©es
            grammar_errors: Les erreurs grammaticales d√©tect√©es
            legal_issues: Les probl√®mes de conformit√© l√©gale d√©tect√©s
            
        Returns:
            Une liste de suggestions d'am√©lioration
        """
        suggestions = []
        
        # Suggestions bas√©es sur les erreurs d'orthographe
        for error in spelling_errors:
            if error.suggestions:
                suggestions.append(f"Orthographe : '{error.word}' pourrait √™tre corrig√© en {', '.join(error.suggestions)}")
        
        # Suggestions bas√©es sur les erreurs grammaticales
        for error in grammar_errors:
            if error.suggestions:
                suggestions.append(f"Grammaire : {error.message} (ex: {', '.join(error.suggestions)})")
        
        # Suggestions bas√©es sur les probl√®mes de conformit√© l√©gale
        for issue in legal_issues:
            if issue.recommendation:
                suggestions.append(f"Conformit√© l√©gale : {issue.recommendation}")
        
        # Suggestions g√©n√©rales d'am√©lioration
        if len(suggestions) == 0:
            suggestions.append("Aucune erreur d√©tect√©e, document potentiellement conforme.")
        elif len(suggestions) <= 2:
            suggestions.append("Peu d'erreurs d√©tect√©es, bon travail !")
        elif len(suggestions) <= 5:
            suggestions.append("Nombre mod√©r√© d'erreurs d√©tect√©es, consid√©rez les corrections sugg√©r√©es.")
        else:
            suggestions.append("Nombre √©lev√© d'erreurs d√©tect√©es, une r√©vision approfondie est recommand√©e.")
        
        return suggestions
    def _load_stop_words(self):
        """
        Charge les mots vides (stop words) en fran√ßais √† ignorer lors de l'analyse
        orthographique et lexicale.
        
        Returns:
            Un ensemble contenant les mots vides fran√ßais
        """
        # Liste de base des mots vides fran√ßais
        stop_words = {
            "le", "la", "les", "un", "une", "des", "du", "de", "ce", "cette", "ces",
            "mon", "ma", "mes", "ton", "ta", "tes", "son", "sa", "ses", "notre", "nos", "votre", "vos", "leur", "leurs",
            "et", "ou", "mais", "donc", "car", "ni", "or", "que", "quoi", "qui", "dont", "o√π",
            "√†", "au", "aux", "avec", "chez", "dans", "de", "depuis", "derri√®re", "devant", "en", "entre", "jusque", "par", "pour", "sans", "sur", "vers",
            "je", "tu", "il", "elle", "on", "nous", "vous", "ils", "elles",
            "me", "te", "se", "lui", "y", "en",
            "√™tre", "avoir", "faire", "dire", "aller", "voir", "pouvoir", "vouloir", "devoir", "falloir",
            "suis", "es", "est", "sommes", "√™tes", "sont", "√©tais", "√©tait", "√©tions", "√©tiez", "√©taient",
            "ai", "as", "a", "avons", "avez", "ont", "avais", "avait", "avions", "aviez", "avaient",
            "fais", "fait", "faisons", "faites", "font", "faisais", "faisait", "faisions", "faisiez", "faisaient",
            "dis", "dit", "disons", "dites", "disent", "disais", "disait", "disions", "disiez", "disaient",
            "vais", "vas", "va", "allons", "allez", "vont", "allais", "allait", "allions", "alliez", "allaient",
            "vois", "voit", "voyons", "voyez", "voient", "voyais", "voyait", "voyions", "voyiez", "voyaient",
            "peux", "peut", "pouvons", "pouvez", "peuvent", "pouvais", "pouvait", "pouvions", "pouviez", "pouvaient",
            "veux", "veut", "voulons", "voulez", "veulent", "voulais", "voulait", "voulions", "vouliez", "voulaient",
            "dois", "doit", "devons", "devez", "doivent", "devais", "devait", "devions", "deviez", "devaient",
            "faut", "fallait"
        }
        
        # Essayer d'utiliser spaCy si disponible pour obtenir une liste plus compl√®te
        try:
            if hasattr(self, 'nlp'):
                # Obtenir les stop words de spaCy
                spacy_stop_words = self.nlp.Defaults.stop_words
                stop_words.update(spacy_stop_words)
        except Exception:
            # En cas d'erreur, utiliser simplement la liste de base
            pass
            
        return stop_words    

    def _is_technical_term(self, word: str) -> bool:
        """
        V√©rifie si un mot est un terme technique qui doit √™tre ignor√© lors de la v√©rification orthographique.
        
        Args:
            word: Le mot √† v√©rifier
            
        Returns:
            True si le mot est un terme technique, False sinon
        """
        if not word:
            return False
            
        # Convertir en minuscule pour la comparaison
        word_lower = word.lower()
        
        # V√©rifier si le mot est dans notre ensemble de termes techniques
        if word_lower in self.technical_terms:
            return True
        
        # V√©rifier si le mot est dans notre cache de termes techniques
        if hasattr(self, 'technical_terms_cache') and word_lower in self.technical_terms_cache:
            return True
            
        # V√©rifier les acronymes (mots en majuscules de 2 caract√®res ou plus)
        if word.isupper() and len(word) >= 2:
            return True
            
        # V√©rifier les termes techniques communs qui incluent des chiffres ou caract√®res sp√©ciaux
        if any(char.isdigit() for char in word) and any(char.isalpha() for char in word):
            return True
            
        # V√©rifier si c'est un terme li√© aux Junior-Entreprises
        je_terms = ["junior", "entreprise", "je", "cnje", "jeh", "urssaf", "siret", "ape", "tva"]
        if any(term in word_lower for term in je_terms):
            return True
            
        # V√©rifier les mots compos√©s avec tiret qui contiennent des termes techniques
        if '-' in word:
            parts = word_lower.split('-')
            return any(part in self.technical_terms for part in parts if part)
        return False
    
    async def _validate_with_mistral(self, words: List[str]) -> Dict[str, bool]:
        """
        Utilise l'API Mistral pour valider si des mots apparemment mal orthographi√©s
        sont en fait des termes techniques, des noms propres, des mots √©trangers, etc.
        
        Args:
            words: Liste des mots √† valider
            
        Returns:
            Dictionnaire avec les mots comme cl√©s et des bool√©ens comme valeurs
            (True si le mot est valide, False sinon)
        """
        if not words:
            return {}
            
        # Limiter le nombre de mots √† valider pour √©viter des requ√™tes trop longues
        max_words_per_batch = 20
        all_validations = {}
        
        # Traiter par lots pour les documents avec beaucoup d'erreurs potentielles
        for i in range(0, len(words), max_words_per_batch):
            batch = words[i:i+max_words_per_batch]
            
            try:
                if not hasattr(self, 'chat_service') or not self.chat_service:
                    # Si le service de chat n'est pas disponible, consid√©rer tous les mots comme valides
                    # pour √©viter des faux positifs
                    batch_validations = {word: True for word in batch}
                else:
                    # Cr√©er le prompt pour Mistral
                    words_list = "\n".join([f"- {word}" for word in batch])
                    prompt = f"""
                    Voici une liste de mots qui ont √©t√© identifi√©s comme potentiellement mal orthographi√©s en fran√ßais :
                    
                    {words_list}
                    
                    Certains peuvent √™tre des termes techniques, des noms propres, des mots √©trangers (notamment anglais), 
                    des acronymes ou des abr√©viations valides. Pour chacun, indique uniquement "VALIDE" si le mot est 
                    correct dans un contexte technique, juridique ou d'entreprise, ou "INVALIDE" s'il s'agit vraiment 
                    d'une faute d'orthographe en fran√ßais. Format attendu:
                    
                    mot1: VALIDE/INVALIDE
                    mot2: VALIDE/INVALIDE
                    etc.
                    """
                    
                    # Appeler l'API Mistral via le service de chat
                    from app.schemas.chat import ChatRequest
                    response = await self.chat_service.process_query(
                        request=ChatRequest(query=prompt),
                        conversation_id=f"spelling_validation_{uuid.uuid4()}",
                        user_id=1  # Utilisateur syst√®me
                    )
                    
                    # Parser la r√©ponse pour extraire les validations
                    if response and hasattr(response, 'answer'):
                        response_text = response.answer
                        batch_validations = {}
                        
                        # Parcourir chaque ligne pour trouver les validations
                        for line in response_text.split('\n'):
                            line = line.strip()
                            if not line or ':' not in line:
                                continue
                                
                            parts = line.split(':', 1)
                            if len(parts) != 2:
                                continue
                                
                            word = parts[0].strip()
                            validation = parts[1].strip().upper()
                            
                            # V√©rifier si le mot est dans notre batch
                            matching_word = next((w for w in batch if w.lower() == word.lower()), None)
                            if matching_word:
                                batch_validations[matching_word] = 'VALIDE' in validation
                        
                        # Pour les mots non trait√©s, les consid√©rer comme valides par d√©faut
                        for word in batch:
                            if word not in batch_validations:
                                batch_validations[word] = True
                    else:
                        # En cas d'erreur, consid√©rer tous les mots comme valides
                        batch_validations = {word: True for word in batch}
                
                all_validations.update(batch_validations)
                
            except Exception as e:
                print(f"Erreur lors de la validation avec Mistral: {str(e)}")
                # En cas d'erreur, consid√©rer tous les mots du batch comme valides
                # pour √©viter des faux positifs
                for word in batch:
                    all_validations[word] = True
        
        return all_validations